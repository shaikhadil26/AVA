{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Defining the initial secondary frame\n",
    "prev_output = None  # To store the previous frame for optical flow comparison\n",
    "\n",
    "# Downloading the MiDaS model\n",
    "midas = torch.hub.load('intel-isl/MiDaS', 'MiDaS_small')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "midas.to(device)\n",
    "midas.eval()\n",
    "\n",
    "transforms = torch.hub.load('intel-isl/MiDaS', 'transforms')\n",
    "transform = transforms.small_transform\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Transforming the image\n",
    "    img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    imgbatch = transform(img).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        prediction = midas(imgbatch)\n",
    "\n",
    "        prediction = torch.nn.functional.interpolate(\n",
    "            prediction.unsqueeze(1),\n",
    "            size=img.shape[:2],\n",
    "            mode='bicubic',\n",
    "            align_corners=False\n",
    "        ).squeeze()\n",
    "\n",
    "        output = prediction.cpu().numpy()\n",
    "\n",
    "        # Normalize output\n",
    "        output_normalized = cv2.normalize(output, None, 0, 255, cv2.NORM_MINMAX)\n",
    "        output_normalized = np.uint8(output_normalized)\n",
    "\n",
    "        # Apply Median filter to preserve edges and reduce noise\n",
    "        output_filtered = cv2.medianBlur(output_normalized, 5)\n",
    "\n",
    "    # If this is the first frame, skip comparison\n",
    "    if prev_output is None:\n",
    "        prev_output = output_filtered\n",
    "        continue\n",
    "\n",
    "    # Optical Flow for pixel-level movement detection (Farneback method)\n",
    "    flow = cv2.calcOpticalFlowFarneback(prev_output, output_filtered, None, \n",
    "                                        0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    mag, _ = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    motion_map = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    motion_map = np.uint8(motion_map)\n",
    "\n",
    "    # Segmenting into panes: left, middle, right\n",
    "    height, width = motion_map.shape\n",
    "    part_width = width // 3\n",
    "\n",
    "    # Slice the motion map into three equal parts\n",
    "    left = motion_map[:, :part_width]\n",
    "    middle = motion_map[:, part_width:2 * part_width]\n",
    "    right = motion_map[:, 2 * part_width:]\n",
    "\n",
    "    # Calculating pixel-level motion in each pane\n",
    "    left_motion = np.mean(left)\n",
    "    middle_motion = np.mean(middle)\n",
    "    right_motion = np.mean(right)\n",
    "\n",
    "    # Dynamic threshold calculation based on standard deviation of motion\n",
    "    motion_avg = np.mean([left_motion, middle_motion, right_motion])\n",
    "    motion_std = np.std([left_motion, middle_motion, right_motion])\n",
    "    dynamic_threshold = motion_avg + motion_std * 0.5  # Adjust factor as needed\n",
    "\n",
    "    alert_messages = []\n",
    "\n",
    "    # Classifying panes where significant motion is detected\n",
    "    if left_motion > dynamic_threshold:\n",
    "        alert_messages.append(\"Obstacle moving in the Left Pane\")\n",
    "        cv2.rectangle(frame, (0, 0), (part_width, height), (0, 0, 255), 2)\n",
    "    if middle_motion > dynamic_threshold:\n",
    "        alert_messages.append(\"Obstacle moving in the Middle Pane\")\n",
    "        cv2.rectangle(frame, (part_width, 0), (2 * part_width, height), (0, 0, 255), 2)\n",
    "    if right_motion > dynamic_threshold:\n",
    "        alert_messages.append(\"Obstacle moving in the Right Pane\")\n",
    "        cv2.rectangle(frame, (2 * part_width, 0), (width, height), (0, 0, 255), 2)\n",
    "\n",
    "    # Display the alert messages for panes where obstacles are moving\n",
    "    for message in alert_messages:\n",
    "        print(message)\n",
    "\n",
    "    # Update the previous frame for optical flow calculation in the next iteration\n",
    "    prev_output = output_filtered\n",
    "\n",
    "    # Display the output depth and motion maps alongside the frame with highlighted panes\n",
    "    cv2.imshow('Depth Prediction (Filtered)', output_filtered)\n",
    "    cv2.imshow('Motion Map', motion_map)\n",
    "    cv2.imshow('CV2Frame', frame)\n",
    "\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
